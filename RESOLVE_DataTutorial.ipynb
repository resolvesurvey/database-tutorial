{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESOLVE Data Tutorial\n",
    "This jupyter notebook illustrates use of the public RESOLVE (REsolved Spectroscopy Of a Local VolumE) survey database, including HI upper limit and confusion information. As of this writing, the HI mass census is fully available (Stark et al. 2016), but HI profile metrics are still being analyzed. The optical spectroscopic census is ~70% complete and is still being reduced and analyzed.<br/>\n",
    "\n",
    "Note that the RESOLVE catalog and all calculations below assume H_0 = 70 km/s/Mpc, implying a combined volume for RESOLVE-A and RESOLVE-B of 52,135 cubic Mpc.<br/>\n",
    "\n",
    "The RESOLVE website at http://resolve.astro.unc.edu/ provides further information, data, and links to papers as well as details on the ECO (Environmental COntext) catalog. ECO is a nearly ten times larger data set surrounding RESOLVE with comparable photometric and environmental data, but it has no new radio or optical spectroscopy beyond SDSS/ALFALFA. A follow-up tutorial demonstrating the use of ECO to correct for cosmic variance in RESOLVE (in the spirit of Eckert et al. 2016) will be provided soon, along with a forthcoming analysis of the bivariate HI mass function comparing RESOLVE and the Simba simulation (Kannappan, Dave, Eckert, et al., in prep.) -- check for updates at the RESOLVE website!\n",
    "\n",
    "Author: Sheila Kannappan<br/>\n",
    "Created: August 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports and naming conventions; uncomment as needed\n",
    "import numpy as np              # basic numerical analysis\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import matplotlib as mp\n",
    "import pred_loggs_dist as pgf # code from Eckert, K.+ 2015 (https://github.com/keckert7/codes)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RESOLVE DR3 csv file is provided in the same github repo as this jupyter notebook, and the README provides instructions to retrieve it. If you wish to obtain a different data release, visit the RESOLVE \"searchable database\" page [here](http://resolve.astro.unc.edu/pages/database.php), which includes all data releases as well as sample sql queries. The simplest possible query, `select *`, will retrieve an entire database (before clicking submit, be sure to switch the output choice from \"browse the results of the query\" to \"download the results of the query (CSV)\"). The [same page](http://resolve.astro.unc.edu/pages/database.php) provides a glossary for each data release. Open the glossary matching the data release you are using in a separate tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next read in RESOLVE DR3 csv file, assuming it is in the same directory as this jupyter notebook\n",
    "# (try alternate syntax below if you get an error message regarding encoding)\n",
    "#data = np.genfromtxt(\"RESOLVE_DR3.csv\", delimiter=\",\", dtype=None, names=True)\n",
    "data = np.genfromtxt(\"RESOLVE_DR3.csv\", delimiter=\",\", dtype=None, names=True, encoding=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at the column names, type `data.dtype.names`, but they should match the glossary [here](http://resolve.astro.unc.edu/pages/database.php) except for possible capitalization differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Selection\n",
    "\n",
    "The RESOLVE database includes galaxies that are not officially part of the survey. They may either have redshifts in the buffer range used for group-finding or have magnitudes fainter than the survey luminosity floor. In some cases data for these galaxies may be useful, but please do not expect all of it to be carefully vetted. We recommend working with one of the following sample definitions to isolate complete, high-quality data sets:<br/><br/>\n",
    "1) the original luminosity- and volume-limited sample: brighter than -17.33 (A-semester) or -17.0 (B-semester) with Grpcz between 4500-7000 km/s<br/>\n",
    "2) the observational sample (for new 21cm and optical spectroscopy): same as #1, but adding in galaxies with known or estimated log(M\\*+1.4MHI)> 9.2 (A-semester) or 9.0 (B-semester) <br/>\n",
    "3) the baryonic mass complete sample: Grpcz between 4500-7000 km/s and log Mbary> 9.3 (A-semester) or 9.1 (B-semester), where Mbary = (M\\*+1.4MHI)<br/>\n",
    "4) the stellar mass complete sample: Grpcz between 4500-7000 km/s and log M\\*> 8.9 (A-semester) or 8.7 (B-semester)<br/><br/>\n",
    "**NOTE 1:** Eckert et al. (2016, 2017) adopted higher baryonic mass completeness limits: log Mbary> 9.4 (for ECO containing RESOLVE-A) and log Mbary> 9.1 (for RESOLVE-B); note however that RESOLVE-A is more complete than ECO as a whole <br/>\n",
    "NOTE 2: To simplify analysis, Stark et al. (2016) adopted a common floor for both RESOLVE-A and RESOLVE-B: log M\\* > 8.9 and log Mbary > 9.3<br/>\n",
    "\n",
    "### We will first select the original luminosity-complete data set (\\#1 above).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpcz = data['grpcz']\n",
    "invol = (grpcz >= 4500) & (grpcz < 7000)\n",
    "fl_insample = data['fl_insample'] # flag for original luminosity limits as in #1 above\n",
    "inorigsample = invol & fl_insample\n",
    "ngal = len(inorigsample)\n",
    "print(\"in catalog %i\" % ngal)\n",
    "print(\"in sample %i\" % np.sum(inorigsample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before looking at the HI data, let's examine the stellar mass, color, and environment properties of this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmstar = data['logmstar']\n",
    "urcolor = data['modelu_r']\n",
    "urcolorcorr = data['modelu_rcorr'] # internal extinction-corrected, useful for sequence separation\n",
    "logmhalo = data['logmh'] # use the groups/halo masses defined for the luminosity-limited sample\n",
    "fc = data['fc'] # central/satellite flag (1/0)\n",
    "cent = (fc == 1)\n",
    "sat = (fc == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally test that these quantities are valid for all original sample galaxies\n",
    "#print(np.sum(logmstar[np.where(inorigsample)] > 0))\n",
    "#print(np.sum(urcolorcorr[np.where(inorigsample)] > 0))\n",
    "#print(np.sum(logmhalo[np.where(inorigsample)] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size' : 20}\n",
    "mp.rc('font', **font)\n",
    "fig1 = plt.figure(1,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmstar[np.where(inorigsample)],urcolor[np.where(inorigsample)],'r.', label=\"apparent color\")\n",
    "plt.plot(logmstar[np.where(inorigsample)],urcolorcorr[np.where(inorigsample)],'b.', label=\"internal extinction-corrected color\")\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"u-r color\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(2,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmhalo[np.where(inorigsample & sat)],logmstar[np.where(inorigsample & sat)],'g.', label=\"satellite\")\n",
    "plt.plot(logmhalo[np.where(inorigsample & cent)],logmstar[np.where(inorigsample & cent)],'g*', markersize=8, label=\"central\")\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"u-r color\")\n",
    "plt.legend(loc=\"best\")\n",
    "print(\"centrals: %i\" % np.sum(cent[np.where(inorigsample)]))\n",
    "print(\"satellites: %i\" % np.sum(sat[np.where(inorigsample)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure serves as a useful reminder that contrary to our intuition, *most galaxies are centrals*. This follows from the steeply rising mass function of parent dark matter halos: at any halo mass, there are many more parent halos than subhalos of higher-mass halos, even though those subhalos obviously outnumber their parent halos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's tackle the HI data. Skip straight to cell 12 if you just want \"the answer\" -- the next four cells show what's under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_0=70. #km/s/Mpc\n",
    "DinMpc = grpcz/H_0\n",
    "f21 = data['f21']\n",
    "logmhi = np.log10(f21 * 2.36e5 * (DinMpc)**2)\n",
    "\n",
    "# first let's see where we started (with ALFALFA)\n",
    "hitelescope = data['hitelescope']\n",
    "limflagmhi = data['limflagmhi']\n",
    "ef21 = data['e_f21']\n",
    "ef21[np.where(ef21 == 0)] = np.nan # unclear why there is a stray zero in ef21, should be NaN\n",
    "notmissing = np.where(~np.isnan(ef21))\n",
    "snr21 = np.zeros(ngal)\n",
    "snr21[notmissing] = f21[notmissing]/ef21[notmissing]\n",
    "sel1 = np.where(inorigsample & (hitelescope == \"ALFALFA\") & (snr21 >= 5) & (limflagmhi == 0)) # note 5 not 6.5\n",
    "sel2 = np.where(inorigsample & (hitelescope == \"ALFALFA\") & (snr21 < 5) & (snr21 > 0) & (limflagmhi == 0))\n",
    "sel3 = np.where(inorigsample & (hitelescope == \"ALFALFA\") & (limflagmhi == 1))\n",
    "hitostars1 = (10**logmhi[sel1]) / (10**logmstar[sel1])\n",
    "hitostars2 = (10**logmhi[sel2]) / (10**logmstar[sel2])\n",
    "hitostars3 = (10**logmhi[sel3]) / (10**logmstar[sel3])\n",
    "print(len(sel1[0]))\n",
    "print(len(sel2[0]))\n",
    "print(len(sel3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(2,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmstar[sel1],hitostars1,'g.', label=\"ALFALFA high SNR\")\n",
    "plt.plot(logmstar[sel2],hitostars2,'g*', markersize=15, markerfacecolor=\"white\", label=\"ALFALFA low SNR (cat?)\")\n",
    "plt.plot(logmstar[sel3],hitostars3,'rv', label=\"ALFALFA upper lim (not cat)\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"HI-to-stellar mass ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new data (detections and upper limits separately)\n",
    "sel4 = np.where(inorigsample & (hitelescope != \"ALFALFA\") & (limflagmhi != 1) & (~np.isnan(ef21))) # again, not missing\n",
    "hitostars4 = (10**logmhi[sel4]) / (10**logmstar[sel4])\n",
    "sel5 = np.where(inorigsample & (hitelescope != \"ALFALFA\") & (limflagmhi == 1))\n",
    "hitostars5 = (10**logmhi[sel5]) / (10**logmstar[sel5])\n",
    "\n",
    "# repeat plot\n",
    "fig3 = plt.figure(3,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmstar[sel1],hitostars1,'g.', label=\"ALFALFA high SNR\")\n",
    "plt.plot(logmstar[sel2],hitostars2,'g*', markersize=15, markerfacecolor=\"white\", label=\"ALFALFA low SNR (cat?)\")\n",
    "plt.plot(logmstar[sel3],hitostars3,'rv', label=\"ALFALFA upper lim (not cat)\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"HI-to-stellar mass ratio\")\n",
    "# add new data to plot\n",
    "plt.plot(logmstar[sel4],hitostars4,'b.', label=\"new high SNR\")\n",
    "plt.plot(logmstar[sel5],hitostars5,'bv', label=\"new upper lim\")\n",
    "\n",
    "print(len(sel4[0]))\n",
    "print(len(sel5[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace confused detections with successfully deconfused data\n",
    "confused = data['confused']\n",
    "f21corr = data['f21corr'] # deconfused flux\n",
    "ef21corr_rand = data['ef21corr_rand'] # random error on deconfused flux\n",
    "ef21corr_sys = data['ef21corr_sys'] # systematic error on deconfused flux\n",
    "f21corr[np.where(f21corr == 0)] = np.nan # treat zero in f21corr as NaN\n",
    "notempty = np.where(~np.isnan(f21corr))\n",
    "deconfokay = np.zeros(ngal,dtype=bool)\n",
    "deconfokay[notempty] = (ef21corr_sys[notempty]/f21corr[notempty]) < 0.25\n",
    "goodconf = (confused == 1) & deconfokay # successfully deconfused\n",
    "badconf = (confused == 1) & ~deconfokay # unsuccessfully deconfused\n",
    "logmhicorr = np.log10(f21corr * 2.36e5 * (DinMpc)**2) # deconfused HI mass\n",
    "\n",
    "notconf = (confused != 1)\n",
    "sel1b = np.where(inorigsample & (hitelescope == \"ALFALFA\") & (snr21 >= 5) & (limflagmhi == 0) & notconf) # note 5 not 6.5\n",
    "sel2b = np.where(inorigsample & (hitelescope == \"ALFALFA\") & (snr21 < 5) & (snr21 > 0) & (limflagmhi == 0) & notconf)\n",
    "sel3b = np.where(inorigsample & (hitelescope == \"ALFALFA\") & (limflagmhi == 1) & notconf) # notconf is unnecessary here\n",
    "sel4b = np.where(inorigsample & (hitelescope != \"ALFALFA\") & (limflagmhi != 1) & (~np.isnan(ef21)) & notconf) # again, not missing\n",
    "sel5b = np.where(inorigsample & (hitelescope != \"ALFALFA\") & (limflagmhi == 1) & notconf) # notconf is unnecessary here\n",
    "hitostars1b = (10**logmhi[sel1b]) / (10**logmstar[sel1b])\n",
    "hitostars2b = (10**logmhi[sel2b]) / (10**logmstar[sel2b])\n",
    "hitostars3b = (10**logmhi[sel3b]) / (10**logmstar[sel3b])\n",
    "hitostars4b = (10**logmhi[sel4b]) / (10**logmstar[sel4b])\n",
    "hitostars5b = (10**logmhi[sel5b]) / (10**logmstar[sel5b])\n",
    "\n",
    "sel6 = np.where(inorigsample & goodconf)\n",
    "hitostars6 = (10**logmhicorr[sel6]) / (10**logmstar[sel6])\n",
    "\n",
    "# will need photometric gas fractions for unsuccessfully deconfused galaxies\n",
    "modeluj = data['modelu_j']\n",
    "b_a=data['b_a']\n",
    "modcolor = 1.140*modeluj + 0.594*(b_a) # from Eckert et al (2015) -- 1D fit with survival analysis on Mgas-to-M* limits\n",
    "photloggovers = 3.659 -0.981*modcolor # from Eckert et al (2015) volume-limited calibration, ~0.3 dex scatter\n",
    "logmhiphot = np.log10((10**photloggovers/1.4) * 10**logmstar) # take out 1.4 for Helium --> just HI\n",
    "\n",
    "sel7 = np.where(inorigsample & badconf)\n",
    "hitostars7 = (10**logmhiphot[sel7]) / (10**logmstar[sel7])\n",
    "\n",
    "# repeat plot replacing confused data with deconfused data or photometric estimates\n",
    "fig4 = plt.figure(4,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmstar[sel1b],hitostars1b,'g.', label=\"ALFALFA high SNR\")\n",
    "plt.plot(logmstar[sel2b],hitostars2b,'g*', markersize=15, markerfacecolor=\"white\", label=\"ALFALFA low SNR (cat?)\")\n",
    "plt.plot(logmstar[sel3b],hitostars3b,'rv', label=\"ALFALFA upper lim (not cat)\")\n",
    "plt.plot(logmstar[sel4b],hitostars4b,'b.', label=\"new high SNR\")\n",
    "plt.plot(logmstar[sel5b],hitostars5b,'bv', label=\"new upper lim\")\n",
    "plt.plot(logmstar[sel6],hitostars6,'mx', markersize=6, label=\"successfully deconfused\")\n",
    "plt.plot(logmstar[sel7],hitostars7,'mx', markersize=6, label=\"badly confused, phot-HI\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"HI-to-stellar mass ratio\")\n",
    "\n",
    "print(len(sel6[0]))\n",
    "print(len(sel7[0]))\n",
    "print(np.sum((confused == 1) & inorigsample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Optimal Combination\n",
    "The cell below combines the HI data for the entire catalog, without reference to a specific subsample until the plot selection commands.\n",
    "\n",
    "**Note**: If you use RESOLVE HI data as described below, please cite Eckert et al. (2015), Stark et al. (2016), and Eckert et al. (2016), respectively, for (i) the photometric gas fraction calibration and code, (ii) the HI data, and (iii) the dividing values used for incorporation of upper limit/confused data. Of course, you may choose to differ from (iii)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestlogmhi = logmhi.copy()\n",
    "# sub in successfully deconfused data\n",
    "bestlogmhi[np.where(goodconf)] = logmhicorr[np.where(goodconf)]\n",
    "# use phot-gas for unsuccessfully deconfused data\n",
    "bestlogmhi[np.where(badconf)] = logmhiphot[np.where(badconf)]\n",
    "# use phot-gas for missing data\n",
    "missing = np.isnan(f21)\n",
    "bestlogmhi[np.where(missing)] = logmhiphot[np.where(missing)]\n",
    "\n",
    "# use *constrained* phot-gas for weak upper limit data\n",
    "weaklimit = np.zeros(ngal,dtype=bool)\n",
    "weaklimit[np.where(limflagmhi == 1)] =  (1.4 * 10**logmhi[np.where(limflagmhi == 1)])/(10**logmstar[np.where(limflagmhi == 1)]) > 0.05\n",
    "# choice of 0.05 follows Eckert et al. 2016 with 1.4 for Helium correction, could make less strict\n",
    "#2D distribution of G/S\n",
    "calibration = 11\n",
    "pars = pgf.getpars(calibration)\n",
    "ploton = 0\n",
    "loggsvals,p_loggs = pgf.estimategovers(modcolor,pars,ploton)\n",
    "# loggsvals = np.arange(-2,2.04,0.04) so 101 edges of 100 bins from -2 to +2\n",
    "# p_loggs is normalized to sum to 1 so is implicitly per 0.04 dex\n",
    "limcount = np.sum(limflagmhi == 1)\n",
    "limind = (np.where(limflagmhi == 1))[0]\n",
    "renorms = np.zeros(limcount)\n",
    "# adjust syntax below for Python 2 or 3 as necessary\n",
    "for j in range(limcount): \n",
    "#for j in xrange(limcount): \n",
    "    if weaklimit[limind[j]]: #renormalize probability distribution to reflect upper limit\n",
    "        lmhi_j = loggsvals - np.log10(1.4) + logmstar[limind[j]] # convert G/S tick marks to HI mass tick marks\n",
    "        p_loggs[np.where(lmhi_j >= logmhi[limind[j]]), limind[j]] = 0 # set probability distribution to 0 above observed limit\n",
    "        renorms[j] = np.sum(p_loggs[np.where(lmhi_j < logmhi[limind[j]]),limind[j]])\n",
    "        p_loggs[np.where(lmhi_j < logmhi[limind[j]]),limind[j]] = p_loggs[np.where(lmhi_j < logmhi[limind[j]]),limind[j]] / renorms[j]\n",
    "        cum_p_loggs = np.cumsum(p_loggs,axis=0)\n",
    "        logmhiphot[limind[j]] = np.interp(0.5,cum_p_loggs[:,limind[j]],lmhi_j) # take median of remaining distribution\n",
    "    else: # this limit is so strong, might as well treat it as a number\n",
    "        logmhiphot[limind[j]] = logmhi[limind[j]] # unused assignment for clarity, strong limits already set to logmhi\n",
    "bestlogmhi[np.where(weaklimit)] = logmhiphot[np.where(weaklimit)]\n",
    "\n",
    "stronglimit = (limflagmhi == 1) & ~weaklimit\n",
    "fakedata = badconf | missing | weaklimit\n",
    "\n",
    "# define selectors for plotting\n",
    "inentiresample = (logmstar != 0)\n",
    "logmbary = np.log10(10**logmstar + 1.4*(10**bestlogmhi)) # bringing back the Helium correction\n",
    "\n",
    "# try running this cell with different options for sample:\n",
    "#insample = inentiresample\n",
    "insample = inorigsample # luminosity limited\n",
    "#insample = (logmbary > 9.3) # baryonic mass limited, ignoring extra depth in RESOLVE-B\n",
    "#insample = (logmstar > 8.9) # stellar mass limited, ignoring extra depth in RESOLVE-B\n",
    "\n",
    "selall = np.where(insample)\n",
    "sellim = np.where(insample & stronglimit)\n",
    "selfake = np.where(insample & fakedata)\n",
    "\n",
    "besthitostars = (10**bestlogmhi) / (10**logmstar)\n",
    "\n",
    "fig5 = plt.figure(5,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmstar[selall],besthitostars[selall],'b.', label=\"good data\")\n",
    "plt.plot(logmstar[sellim],besthitostars[sellim],'rv', label=\"upper limit\")\n",
    "plt.plot(logmstar[selfake],besthitostars[selfake],'m*', label=\"phot-HI\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"HI-to-stellar mass ratio\")\n",
    "\n",
    "print(np.sum(insample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to the original\n",
    "fig2 = plt.figure(2,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmstar[sel1],hitostars1,'g.', label=\"ALFALFA high SNR\")\n",
    "plt.plot(logmstar[sel2],hitostars2,'g*', markersize=15, markerfacecolor=\"white\", label=\"ALFALFA low SNR (cat?)\")\n",
    "plt.plot(logmstar[sel3],hitostars3,'rv', label=\"ALFALFA upper lim (not cat)\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"log stellar mass\")\n",
    "plt.ylabel(\"HI-to-stellar mass ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As an r-band selected survey, RESOLVE is most fundamentally baryonic mass limited. Below is a plot as a function of baryonic rather than stellar mass, showing all galaxies in the original luminosity-complete sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insample = inorigsample\n",
    "selall = np.where(insample)\n",
    "sellim = np.where(insample & stronglimit)\n",
    "selfake = np.where(insample & fakedata)\n",
    "\n",
    "fig6 = plt.figure(6,figsize=(10,7))\n",
    "plt.clf()\n",
    "plt.plot(logmbary[selall],1.4*besthitostars[selall],'b.', label=\"good data\")\n",
    "plt.plot(logmbary[sellim],1.4*besthitostars[sellim],'rv', label=\"upper limit\")\n",
    "plt.plot(logmbary[selfake],1.4*besthitostars[selfake],'m*', label=\"phot-HI\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"log baryonic mass\")\n",
    "plt.ylabel(\"atomic gas-to-stellar mass ratio\")\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(9.3,ylim[0],ylim[1],linestyle=\"--\",linewidth=5) # plot completeness limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice RESOLVE has a LOT more HI data in the luminosity-complete sample than the baryonic mass-complete sample. This is due to the non-negligible scatter in baryonic mass-to-light ratio. There are even a few galaxies above the baryonic mass limit with luminosity below the original sample floor (picked up by our observational selection strategy, sample #2 defined at the top of this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun Result (Hood et al. 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_type = data['tf_type']\n",
    "tf_conf = data['tf_confidence']\n",
    "tidfeat = (tf_conf == 4) | (tf_conf == 3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
